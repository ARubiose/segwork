{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=3,                      # model output channels (number of classes in your dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext101_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_32x16d',\n",
       " 'resnext101_32x32d',\n",
       " 'resnext101_32x48d',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'senet154',\n",
       " 'se_resnet50',\n",
       " 'se_resnet101',\n",
       " 'se_resnet152',\n",
       " 'se_resnext50_32x4d',\n",
       " 'se_resnext101_32x4d',\n",
       " 'densenet121',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenet161',\n",
       " 'inceptionresnetv2',\n",
       " 'inceptionv4',\n",
       " 'efficientnet-b0',\n",
       " 'efficientnet-b1',\n",
       " 'efficientnet-b2',\n",
       " 'efficientnet-b3',\n",
       " 'efficientnet-b4',\n",
       " 'efficientnet-b5',\n",
       " 'efficientnet-b6',\n",
       " 'efficientnet-b7',\n",
       " 'mobilenet_v2',\n",
       " 'xception',\n",
       " 'timm-efficientnet-b0',\n",
       " 'timm-efficientnet-b1',\n",
       " 'timm-efficientnet-b2',\n",
       " 'timm-efficientnet-b3',\n",
       " 'timm-efficientnet-b4',\n",
       " 'timm-efficientnet-b5',\n",
       " 'timm-efficientnet-b6',\n",
       " 'timm-efficientnet-b7',\n",
       " 'timm-efficientnet-b8',\n",
       " 'timm-efficientnet-l2',\n",
       " 'timm-tf_efficientnet_lite0',\n",
       " 'timm-tf_efficientnet_lite1',\n",
       " 'timm-tf_efficientnet_lite2',\n",
       " 'timm-tf_efficientnet_lite3',\n",
       " 'timm-tf_efficientnet_lite4',\n",
       " 'timm-resnest14d',\n",
       " 'timm-resnest26d',\n",
       " 'timm-resnest50d',\n",
       " 'timm-resnest101e',\n",
       " 'timm-resnest200e',\n",
       " 'timm-resnest269e',\n",
       " 'timm-resnest50d_4s2x40d',\n",
       " 'timm-resnest50d_1s4x24d',\n",
       " 'timm-res2net50_26w_4s',\n",
       " 'timm-res2net101_26w_4s',\n",
       " 'timm-res2net50_26w_6s',\n",
       " 'timm-res2net50_26w_8s',\n",
       " 'timm-res2net50_48w_2s',\n",
       " 'timm-res2net50_14w_8s',\n",
       " 'timm-res2next50',\n",
       " 'timm-regnetx_002',\n",
       " 'timm-regnetx_004',\n",
       " 'timm-regnetx_006',\n",
       " 'timm-regnetx_008',\n",
       " 'timm-regnetx_016',\n",
       " 'timm-regnetx_032',\n",
       " 'timm-regnetx_040',\n",
       " 'timm-regnetx_064',\n",
       " 'timm-regnetx_080',\n",
       " 'timm-regnetx_120',\n",
       " 'timm-regnetx_160',\n",
       " 'timm-regnetx_320',\n",
       " 'timm-regnety_002',\n",
       " 'timm-regnety_004',\n",
       " 'timm-regnety_006',\n",
       " 'timm-regnety_008',\n",
       " 'timm-regnety_016',\n",
       " 'timm-regnety_032',\n",
       " 'timm-regnety_040',\n",
       " 'timm-regnety_064',\n",
       " 'timm-regnety_080',\n",
       " 'timm-regnety_120',\n",
       " 'timm-regnety_160',\n",
       " 'timm-regnety_320',\n",
       " 'timm-skresnet18',\n",
       " 'timm-skresnet34',\n",
       " 'timm-skresnext50_32x4d',\n",
       " 'timm-mobilenetv3_large_075',\n",
       " 'timm-mobilenetv3_large_100',\n",
       " 'timm-mobilenetv3_large_minimal_100',\n",
       " 'timm-mobilenetv3_small_075',\n",
       " 'timm-mobilenetv3_small_100',\n",
       " 'timm-mobilenetv3_small_minimal_100',\n",
       " 'timm-gernet_s',\n",
       " 'timm-gernet_m',\n",
       " 'timm-gernet_l']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(smp.encoders.encoders.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "smp.encoders.encoders = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Wrong encoder name `resnet34`, supported encoders: []'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mf:\\Desarrollo software\\segwork\\.venv\\lib\\site-packages\\segmentation_models_pytorch\\encoders\\__init__.py:61\u001b[0m, in \u001b[0;36mget_encoder\u001b[1;34m(name, in_channels, depth, weights, output_stride, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/encoders/__init__.py?line=59'>60</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/encoders/__init__.py?line=60'>61</a>\u001b[0m     Encoder \u001b[39m=\u001b[39m encoders[name][\u001b[39m\"\u001b[39m\u001b[39mencoder\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/encoders/__init__.py?line=61'>62</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'resnet34'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mf:\\Desarrollo software\\segwork\\notebooks\\smp.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Desarrollo%20software/segwork/notebooks/smp.ipynb#ch0000005?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m smp\u001b[39m.\u001b[39;49mUnet(\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Desarrollo%20software/segwork/notebooks/smp.ipynb#ch0000005?line=1'>2</a>\u001b[0m     encoder_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mresnet34\u001b[39;49m\u001b[39m\"\u001b[39;49m,        \u001b[39m# choose encoder, e.g. mobilenet_v2 or efficientnet-b7\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Desarrollo%20software/segwork/notebooks/smp.ipynb#ch0000005?line=2'>3</a>\u001b[0m     encoder_weights\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mimagenet\u001b[39;49m\u001b[39m\"\u001b[39;49m,     \u001b[39m# use `imagenet` pre-trained weights for encoder initialization\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Desarrollo%20software/segwork/notebooks/smp.ipynb#ch0000005?line=3'>4</a>\u001b[0m     in_channels\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,                  \u001b[39m# model input channels (1 for gray-scale images, 3 for RGB, etc.)\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Desarrollo%20software/segwork/notebooks/smp.ipynb#ch0000005?line=4'>5</a>\u001b[0m     classes\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,                      \u001b[39m# model output channels (number of classes in your dataset)\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Desarrollo%20software/segwork/notebooks/smp.ipynb#ch0000005?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[1;32mf:\\Desarrollo software\\segwork\\.venv\\lib\\site-packages\\segmentation_models_pytorch\\unet\\model.py:65\u001b[0m, in \u001b[0;36mUnet.__init__\u001b[1;34m(self, encoder_name, encoder_depth, encoder_weights, decoder_use_batchnorm, decoder_channels, decoder_attention_type, in_channels, classes, activation, aux_params)\u001b[0m\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=49'>50</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=50'>51</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=51'>52</a>\u001b[0m     encoder_name: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mresnet34\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=60'>61</a>\u001b[0m     aux_params: Optional[\u001b[39mdict\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=61'>62</a>\u001b[0m ):\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=62'>63</a>\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m---> <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=64'>65</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m get_encoder(\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=65'>66</a>\u001b[0m         encoder_name,\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=66'>67</a>\u001b[0m         in_channels\u001b[39m=\u001b[39;49min_channels,\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=67'>68</a>\u001b[0m         depth\u001b[39m=\u001b[39;49mencoder_depth,\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=68'>69</a>\u001b[0m         weights\u001b[39m=\u001b[39;49mencoder_weights,\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=69'>70</a>\u001b[0m     )\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=71'>72</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder \u001b[39m=\u001b[39m UnetDecoder(\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=72'>73</a>\u001b[0m         encoder_channels\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mout_channels,\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=73'>74</a>\u001b[0m         decoder_channels\u001b[39m=\u001b[39mdecoder_channels,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=77'>78</a>\u001b[0m         attention_type\u001b[39m=\u001b[39mdecoder_attention_type,\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=78'>79</a>\u001b[0m     )\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=80'>81</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msegmentation_head \u001b[39m=\u001b[39m SegmentationHead(\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=81'>82</a>\u001b[0m         in_channels\u001b[39m=\u001b[39mdecoder_channels[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=82'>83</a>\u001b[0m         out_channels\u001b[39m=\u001b[39mclasses,\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=83'>84</a>\u001b[0m         activation\u001b[39m=\u001b[39mactivation,\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=84'>85</a>\u001b[0m         kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/unet/model.py?line=85'>86</a>\u001b[0m     )\n",
      "File \u001b[1;32mf:\\Desarrollo software\\segwork\\.venv\\lib\\site-packages\\segmentation_models_pytorch\\encoders\\__init__.py:63\u001b[0m, in \u001b[0;36mget_encoder\u001b[1;34m(name, in_channels, depth, weights, output_stride, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/encoders/__init__.py?line=60'>61</a>\u001b[0m     Encoder \u001b[39m=\u001b[39m encoders[name][\u001b[39m\"\u001b[39m\u001b[39mencoder\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/encoders/__init__.py?line=61'>62</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/encoders/__init__.py?line=62'>63</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWrong encoder name `\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m`, supported encoders: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, \u001b[39mlist\u001b[39m(encoders\u001b[39m.\u001b[39mkeys())))\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/encoders/__init__.py?line=64'>65</a>\u001b[0m params \u001b[39m=\u001b[39m encoders[name][\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     <a href='file:///f%3A/Desarrollo%20software/segwork/.venv/lib/site-packages/segmentation_models_pytorch/encoders/__init__.py?line=65'>66</a>\u001b[0m params\u001b[39m.\u001b[39mupdate(depth\u001b[39m=\u001b[39mdepth)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Wrong encoder name `resnet34`, supported encoders: []'"
     ]
    }
   ],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=3,                      # model output channels (number of classes in your dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f915bd14e41f75defdaded59260e23886f79ad3e68b01e8dfe9aedb79f73e220"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
